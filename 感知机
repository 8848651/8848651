import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
iris = pd.read_csv('diabetes.csv')
iris =np.array(iris)
#iris.data大小为150*4,代表4种特征
#这里只提取后两类特征
X = iris[:,[1,7]]
y = iris[:,8]
#划分训练集和测试集
#random_state = 0表示不设定随机数种子,每一次产生的随机数不一样
X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)
plt.subplot(1, 2, 1)
index_c0, index_c1 = (y_test == 0), (y_test == 1)
c0, c1= X_test[index_c0], X_test[index_c1]
plt.scatter(c0[:, 0], c0[:, 1], marker='s')
plt.scatter(c1[:, 0], c1[:, 1], marker='o')
# 为了追求机器学习和最优化算法的最佳性能，我们将特征缩放
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit(X_train) # 估算每个特征的平均值和标准差
#标准化训练集
X_train_std = sc.transform(X_train)
# 注意：这里我们要用同样的参数来标准化测试集，使得测试集和训练集之间有可比性
X_test_std = sc.transform(X_test)
# 训练感知机模型
from sklearn.linear_model import Perceptron
# n_iter：可以理解成梯度下降中迭代的次数
# eta0：可以理解成梯度下降中的学习率
# random_state：设置随机种子的，为了每次迭代都有相同的训练集顺序
ppn = Perceptron(max_iter=40, eta0=0.1, random_state=0)
ppn.fit(X_train_std, y_train)
# 分类测试集，这将返回一个测试结果的数组
y_pred = ppn.predict(X_test_std)
plt.subplot(1, 2, 2)
index_c2, index_c3 = (y_pred == 0), (y_pred == 1)
c2, c3= X_test[index_c2], X_test[index_c3]
plt.scatter(c2[:, 0], c2[:, 1], marker='s')
plt.scatter(c3[:, 0], c3[:, 1], marker='o')
# 计算模型在测试集上的准确性
m=accuracy_score(y_test, y_pred)
print(m)
plt.legend()
plt.tight_layout()
plt.show()
